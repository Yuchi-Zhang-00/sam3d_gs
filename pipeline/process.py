import os
os.environ["PYOPENGL_PLATFORM"] = "egl"
import glob
import argparse
import numpy as np
from scipy.spatial.transform import Rotation as R
import torch
from pipeline.utils import clean_name, load_image, load_binary_mask, collect_mask_paths, compute_fov_from_intrinsics, mesh_rendering, mesh_rendering_with_depth_adjustment
from inference import (
    Inference,
    make_scene,
    transform_mesh,
    ready_gaussian_for_video_rendering,
    render_video,
    interactive_visualizer,
    _fix_gaussian_alignment
)
from PIL import Image
import cv2

def main():
    parser = argparse.ArgumentParser(
        description="Run SAM3D multi-object inference and save outputs to .pt, and reconstruct single object Gaussian .ply"
    )
    parser.add_argument(
        "--project-root",
        type=str,
        default="sam-3d-objects",
        help="Root directory of sam-3d-objects project.",
    )
    parser.add_argument(
        "--save-dir",
        type=str,
        default="sam-3d-objects/torch_save_pt",
        help="Directory containing *.pt files.",
    )
    parser.add_argument(
        "--image-path",
        type=str,
        default="sam3/assets/img.jpg",
        help="Original image path (Input image path to lift to 3D.).",
    )
    # parser.add_argument(
    #     "--mask-root",
    #     type=str,
    #     default="sam3/agent_output_multi/masks",
    #     help="Directory containing mask PNG/JPGs.",
    # )
    parser.add_argument(
        "--tag",
        type=str,
        default="hf",
        help="Checkpoint tag, corresponds to ../sam-3d-objects/checkpoints/{tag}/pipeline.yaml",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed passed into Inference.__call__.",
    )
    
    args = parser.parse_args()

    script_dir = os.path.dirname(os.path.abspath(__file__))

    if args.project_root is not None:
        # å¦‚æœç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œæ˜¾å¼ä¼ å…¥äº† --project-rootï¼Œå°±ç›´æ¥ç”¨å®ƒ
        project_root = os.path.abspath(args.project_root)
    else:
        # å¦åˆ™è‡ªåŠ¨æ¨æ–­ï¼šå‡è®¾å½“å‰è„šæœ¬ä½äº sam3d_gs/pipeline/ ä¸‹ï¼Œ
        # sam-3d-objects ä½äº sam3d_gs/sam-3d-objects
        project_root = os.path.abspath(os.path.join(script_dir, "..", "sam-3d-objects"))

    print(f"Project root (sam-3d-objects): {project_root}")

    config_path = os.path.join(project_root, "checkpoints", args.tag, "pipeline.yaml")
    print(f"Using config: {config_path}")
    inference = Inference(config_path, compile=False)

    # è¯»å–å›¾åƒ
    pil_image = load_image(args.image_path)
    image_bg = np.array(pil_image)

    # mask_paths = collect_mask_paths(args.mask_root)
    # è·å–å›¾åƒæ–‡ä»¶æ‰€åœ¨ç›®å½•
    image_dir = os.path.dirname(args.image_path)
    # æ„å»º mask ç›®å½•è·¯å¾„ï¼ˆä¸ image_path åŒçº§ï¼‰
    mask_dir = os.path.join(image_dir, 'masks')
    # ä» mask ç›®å½•æ”¶é›† mask è·¯å¾„
    mask_paths = collect_mask_paths(mask_dir)
    # æ„å»º 3D èµ„äº§ è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆä¸ image_path åŒçº§ï¼‰
    assets_dir = os.path.join(image_dir, '3d_assets')
    # æ„å»º pt ä¿å­˜è·¯å¾„ï¼ˆä¸ image_path åŒçº§ï¼‰
    pt_dir = os.path.join(image_dir, 'pt')

    if not mask_paths:
        # raise RuntimeError(f"No mask images found under {args.mask_root}")
        raise RuntimeError(f"No mask images found under {mask_dir}")

    # è·å–å›¾åƒæ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰ï¼Œç”¨äºåˆ›å»ºæ–‡ä»¶å¤¹
    # image_name = os.path.splitext(os.path.basename(args.image_path))[0]
    # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
    # image_name_clean = clean_name(image_name)
    # åˆ›å»ºå›¾åƒåå¯¹åº”çš„æ–‡ä»¶å¤¹
    # image_output_dir = os.path.join(args.save_dir, image_name_clean)

    # os.makedirs(image_output_dir, exist_ok=True)
    os.makedirs(assets_dir, exist_ok=True)
    os.makedirs(pt_dir, exist_ok=True)

    extrinsics = np.load(os.path.join(image_dir, 'extrinsic.npy'))
    intrinsics = np.load(os.path.join(image_dir, 'intrinsic.npy'))
    depth_anysplat      = np.load(os.path.join(image_dir, 'depth.npy'))

    # æ‰“å°ä¿¡æ¯ (å·²ä¿®æ­£æ ‡ç­¾é”™è¯¯)
    print("extrinsics", type(extrinsics), extrinsics) 
    print("intrinsics", type(intrinsics), intrinsics) # ä¿®æ­£äº†è¿™é‡Œçš„å­—ç¬¦ä¸²
    print("depth_anysplat shape", depth_anysplat.shape)

    image_size = (448, 448)

    # # 1. ä»å½’ä¸€åŒ–å†…å‚çŸ©é˜µæå–å€¼
    # fx_norm = intrinsics[0, 0]
    # fy_norm = intrinsics[1, 1]

    # # 2. è½¬æ¢ä¸ºåƒç´ ç„¦è·
    # fx_pixels = fx_norm * (image_size[1] / 2.0)  # ä¹˜ä»¥å®½åº¦/2
    # fy_pixels = fy_norm * (image_size[0] / 2.0)  # ä¹˜ä»¥é«˜åº¦/2

    fx_pixels = intrinsics[0, 0]
    fy_pixels = intrinsics[1, 1]

    # print(f"å½’ä¸€åŒ–ç„¦è·: fx={fx_norm:.4f}, fy={fy_norm:.4f}")
    print(f"åƒç´ ç„¦è·: fx={fx_pixels:.2f}, fy={fy_pixels:.2f}")

    # 3. ä½¿ç”¨åƒç´ ç„¦è·è®¡ç®—çœŸå®çš„FOV
    fov_x, fov_y = compute_fov_from_intrinsics(fx_pixels, fy_pixels, image_size, degrees=True)

    print(f"å‚ç›´FOV: {fov_y:.2f}åº¦")
    print(f"æ°´å¹³FOV: {fov_x:.2f}åº¦")

    camera_to_world = np.linalg.inv(extrinsics)  # shape (4, 4)

    rotation_mat = camera_to_world[:3, :3]
    translation_vec = camera_to_world[:3, 3]

    mean_depths_ori = []
    min_depths_ori = []
    max_depths_ori = []
    # for i,item in enumerate(mask_names):
    #     print(f"{i} {item}")
    #     depth_fg = depth[masks[i]]

    #     mean_depth_ori = depth_fg.mean()
    #     mean_depths_ori.append(mean_depth_ori)
    #     min_depth_ori = depth_fg.min()
    #     min_depths_ori.append(min_depth_ori)
    #     max_depth_ori = depth_fg.max()
    #     max_depths_ori.append(max_depth_ori)

    mask_names = []
    masks = []
    original_sizes = []

    device = "cuda" if torch.cuda.is_available() else "cpu"

    for i, mask_path in enumerate(mask_paths):
        print(f"[{i+1}/{len(mask_paths)}] running inference on mask: {mask_path}")

        # mask = load_binary_mask(mask_path)
        mask_ = np.array(Image.open(mask_path).convert("L"))
        mask = np.where(mask_ > 0, 1, 0).astype("uint8")
        print(f"mask çš„value {np.unique(mask)}")
        size_ori = np.sum(mask)
        original_sizes.append(size_ori)
        masks.append(mask)
        print(f"depth_anysplat shape: {depth_anysplat.shape}")
        print(f"depth_anysplat dtype: {depth_anysplat.dtype}")
        depth_fg = depth_anysplat[mask]
        # print(depth_fg)
        mean_depth_ori = depth_fg.mean()
        min_depth_ori = depth_fg.min()
        max_depth_ori = depth_fg.max()
        print(f"anyplat mean_depth_ori: {mean_depth_ori:.4f}, min_depth_ori: {min_depth_ori:.4f}, max_depth_ori: {max_depth_ori:.4f}")
        # æ„é€ ä¿å­˜åå­—ï¼šä½¿ç”¨maskæ–‡ä»¶åï¼ˆæ— æ‰©å±•åï¼‰.pt
        mask_stem_raw = os.path.splitext(os.path.basename(mask_path))[0]
        mask_stem = clean_name(mask_stem_raw)
        mask_names.append(mask_stem)
        cv2.imwrite(os.path.join(image_dir, f"{mask_stem}_binary.png"),mask*255)
        save_name = f"{mask_stem}.pt"
        # ä¿å­˜åˆ°å›¾åƒåå¯¹åº”çš„æ–‡ä»¶å¤¹ä¸­
        save_path = os.path.join(pt_dir, save_name)

        if os.path.exists(save_path):
            print(f"âœ… Loading existing .pt file: {save_path}")
            out = torch.load(save_path, map_location=device,weights_only=False)
        else:
            out = inference(image_bg, mask, seed=args.seed)       
            torch.save(out, save_path)
            print(f"âœ… Saved: {save_path}")

        # # è¾“å‡ºout çš„dicté”®
        # print(f"  Output keys: {list(out.keys())}")

        # æ ¹æ®outçš„ä½å§¿å°†Gaussianè½¬æ¢åˆ°sam3dä¼°è®¡çš„ä½å§¿
        single_scene = make_scene(out)
        # æ”¹åŠ¨xï¼Œzè½´æœå‘ä¸anysplatçš„ç»“æœå¯¹é½ ï¼ˆxå³yä¸‹zå‰ï¼‰
        xyz = single_scene.get_xyz
        xyz_cv = xyz.clone()
        xyz_cv[:, 1] = -xyz[:, 1]  # Yè½´ç¿»è½¬      
        xyz_cv[:, 0] = -xyz[:, 0]  # Xè½´ç¿»è½¬
        single_scene.from_xyz(xyz_cv)

        # stem = os.path.splitext(os.path.basename(p))[0]
        # single_ply_path = os.path.join(single_gauss_dir, f"{stem}.ply")
        single_ply_path = os.path.join(assets_dir, f"{mask_stem}_gs_sam3d_target.ply")
        single_scene.save_ply(single_ply_path)
        # print(f"ğŸŸ¢ Saved single-object PLY: {single_ply_path}")
        
        # è¾“å‡ºæœªç»transformçš„Gaussian
        untransforrmed_ply_path = os.path.join(assets_dir, f"{mask_stem}_gs_untransformed.ply")
        # out["gs"].save_ply(untransforrmed_ply_path)
        print(f"ğŸŸ¢ Saved untransformed single-object PLY: {untransforrmed_ply_path}")
        
        # æ‰“å°objectçš„poseï¼Œscale
        rotation = out['rotation']
        translation = out['translation']
        scale = out['scale']
        # print(f" rotation: {out['rotation']}")
        # print(f" translation: {out['translation']}")
        # print(f" scale: {out['scale']}")            
        
        if out['glb']:              # å¦‚æœè¾“å‡ºåŒ…å«mesh
            mesh = out['glb']
            untransformed_mesh_path = os.path.join(assets_dir, f"{mask_stem}_mesh_untransformed.obj")
            # mesh.export(untransformed_mesh_path)
            print(f"ğŸŸ¢ Saved untransformed object Mesh: {untransformed_mesh_path}")
            
            # è¾“å‡ºçš„meshåœ¨trimeshåæ ‡ç³»ä¸‹ï¼Œå°†å…¶è½¬å‘è¾“å‡ºGaussiançš„åˆå§‹åæ ‡ç³» 
            rot_coordinate_transform = np.array([
                [1, 0, 0, 0],
                [0, 0, 1, 0],
                [0, 1, 0, 0],
                [0, 0, 0, 1]
            ]) 
            first_transformed_mesh_path = os.path.join(assets_dir, f"{mask_stem}_mesh_cooridnates_aligned.obj")
            mesh.apply_transform(rot_coordinate_transform)
            # mesh.export(first_transformed_mesh_path)
            print(f"ğŸŸ¢ Saved object mesh whose coordinate aligned with gaussian's: {first_transformed_mesh_path}")
            
            # 1. å¤„ç†æ—‹è½¬ï¼šå››å…ƒæ•° â†’ æ—‹è½¬çŸ©é˜µ
            quat = out["rotation"].cpu().numpy()  # pytorch3dä¸­å››å…ƒæ•°[w, x, y, z]
            rot = R.from_quat(quat,scalar_first=True).as_matrix().squeeze(0) # 3x3

            inverse_rot = np.linalg.inv(rot)
            # 2. å¤„ç†ç¼©æ”¾
            scale = out["scale"].squeeze(0).cpu().numpy() 
            if np.isscalar(scale):
                scale = np.array([scale, scale, scale])
            else:
                scale = np.asarray(scale)
            
            # æ„å»ºç¼©æ”¾çŸ©é˜µï¼ˆ3x3ï¼‰
            scale_mat = np.diag(scale)

            # 3. ç»„åˆæ—‹è½¬ + ç¼©æ”¾ï¼šå…ˆç¼©æ”¾ï¼Œå†æ—‹è½¬ï¼ˆé€šå¸¸é¡ºåºï¼‰
            # å³ï¼šR @ S ï¼ˆå¯¹ç‚¹ pï¼šp' = R @ (S @ p) = (R @ S) @ pï¼‰
            # rot_scale = rot @ scale_mat  # 3x3  

            # 4. æ„å»º 4x4 é½æ¬¡å˜æ¢çŸ©é˜µ
            transform = np.eye(4)
            transform[:3, :3] = inverse_rot @ scale_mat
            transform[:3, 3] = out["translation"].cpu().numpy() 

            # 5. åº”ç”¨å˜æ¢åˆ° mesh
            mesh.apply_transform(transform)
            # x, yè½´å–åï¼Œæœå‘ç›®æ ‡åæ ‡ç³»ï¼ˆxå³ï¼Œyä¸‹ï¼Œzå‰ï¼‰
            mesh.vertices[:,1] = -mesh.vertices[:,1]
            mesh.vertices[:,0] = -mesh.vertices[:,0]
            # single_mesh_path = os.path.join(single_gauss_dir, f"{stem}-yz-inverse3.obj")
            single_mesh_path = os.path.join(assets_dir, f"{mask_stem}_mesh_sam3d_taget.obj")
            mesh.export(single_mesh_path)
            # print(f"ğŸŸ¢ Saved single-object Mesh: {single_mesh_path}")
            # color, depth, scale, z_shift = mesh_rendering_with_depth_adjustment(mesh=mesh, extrinsics=extrinsics, fov_y=fov_y, original_mean_depth=mean_depth_ori,original_size=size_ori)
            mesh_copy = mesh.copy()
            color, depth = mesh_rendering(mesh=mesh_copy,extrinsics=extrinsics,fov_y=fov_y/180*np.pi)
            mean_depth_sam3d = np.mean(depth[depth > 0])
            # z_shift = mean_depth_ori - mean_depth_sam3d
            z_shift = min_depth_ori - mean_depth_sam3d
            print(f" z_shift:{ z_shift}, mean_depth_sam3d: {mean_depth_sam3d}, mean_depth_ori: {mean_depth_ori}")
            mesh.vertices= mesh.vertices + np.array([0, 0, z_shift])
            mesh_copy = mesh.copy()
            color, depth = mesh_rendering(mesh=mesh_copy,extrinsics=extrinsics,fov_y=fov_y/180*np.pi)
            depth_fg = depth[depth > 0]
            size_new = np.sum(depth > 0)
            scale = size_ori/size_new
            print(f"mask_stem: {mask_stem}", "size_ori:", size_ori, "size_new:", size_new, "scale:", scale, "z_shift:", z_shift)
            mesh.vertices = mesh.vertices * scale
            mesh_copy = mesh.copy()
            color, depth = mesh_rendering(mesh=mesh_copy,extrinsics=extrinsics,fov_y=fov_y/180*np.pi)
            mean_depth_sam3d_2 = np.mean(depth[depth > 0])
            z_shift_2 = mean_depth_ori - mean_depth_sam3d_2
            # z_shift_2 = min_depth_ori - mean_depth_sam3d_2
            mesh.vertices= mesh.vertices + np.array([0, 0, z_shift_2])
            # meshå·²ç»æ ¹æ®z_shiftå’Œscaleè°ƒæ•´è¿‡äº†ï¼Œç°åœ¨å°†Gaussianè¿›è¡ŒåŒæ ·çš„è°ƒæ•´
            xyz = single_scene.get_xyz
            xyz_cv = xyz.clone()
            xyz_cv[:, 2] = xyz[:, 2] + z_shift  # åœ¨Zæ–¹å‘ä¸Šç¬¬ä¸€æ¬¡ç§»åŠ¨
            xyz_cv = xyz_cv * scale
            # xyz_cv[:, 2] = xyz[:, 2] + z_shift_2  # åœ¨Zæ–¹å‘ä¸Šç¬¬äºŒæ¬¡ç§»åŠ¨   å› ä¸ºmeshç§»åŠ¨äº†ä¸¤æ¬¡
            single_scene.from_xyz(xyz_cv)
            adjust_scale = single_scene.get_scaling * scale
            single_scene.mininum_kernel_size *= scale
            single_scene.from_scaling(adjust_scale)
            xyz = single_scene.get_xyz
            xyz_cv = xyz.clone()
            xyz_cv[:, 2] = xyz[:, 2] + z_shift_2  # åœ¨Zæ–¹å‘ä¸Šç¬¬äºŒæ¬¡ç§»åŠ¨   å› ä¸ºmeshç§»åŠ¨äº†ä¸¤æ¬¡
            single_scene.from_xyz(xyz_cv)
            single_ply_path = os.path.join(assets_dir, f"{mask_stem}_gs_final.ply")
            single_scene.save_ply(single_ply_path)
            print(f"ğŸŸ¢ Saved transformed object PLY: {single_ply_path}")

            transformed_mesh_path = os.path.join(assets_dir, f"{mask_stem}_mesh_final.obj")
            mesh.export(transformed_mesh_path)
            print(f"ğŸŸ¢ Saved transformed object mesh: {transformed_mesh_path}")

            





        # å¦‚æœæ˜¾å­˜å¾ˆç´§å¼ ï¼Œå¯ä»¥åœ¨è¿™é‡Œ del single_scene / video ç­‰
        del single_scene

        # æ˜¾å¼é‡Šæ”¾æ˜¾å­˜
        del out
        torch.cuda.empty_cache()

    print("âœ… All objects processed and saved as .pt")

    # project_root = args.project_root
    # image_path = args.image_path
    # image_name = os.path.basename(os.path.dirname(image_path))

    # è¯»å–å›¾åƒ
    # img1 = cv2.imread('/home/discover/sam3d_gs/bg-rgb/new-desk-o.jpg')
    # mask_names = ['pot','bottle','duster']
    # mask_paths = []
    # mesh_paths = []
    # masks = []
    # original_size = []
    # for i,item in enumerate(mask_names):
    #     mask_path = f'/home/discover/sam3d_gs/masks/new-desk/{item}.png'
    #     mask_paths.append(mask_path)
    #     mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    #     valid_mask = np.where(mask>0, 1, 0).astype(np.uint8)
    #     masks.append(valid_mask)
    #     original_size.append(np.sum(valid_mask))
    #     # mesh_path = f'/home/discover/sam3d_gs/masks/new-desk/newdesk_{item}-mesh_untransformed_trans.obj'
    #     mesh_path = f'/home/discover/sam3d_gs/sam-3d-objects/gaussians/single/newdesk_{item}-mesh-transformed.obj'
    #     mesh_paths.append(mesh_path)

    

    # # è¿™é‡Œä¸å†é™å®š object_*.ptï¼Œè€Œæ˜¯æŠŠ save-dir/image_name ä¸‹æ‰€æœ‰ .pt éƒ½åƒæ‰
    # paths = sorted(glob.glob(os.path.join(pt_dir, "*.pt")))
    # if not paths:
    #     raise RuntimeError(f"No .pt found under {args.save_dir}")

    # print(f"Found {len(paths)} .pt files:")
    # for p in paths:
    #     print("  ", p)

    # device = "cuda" if torch.cuda.is_available() else "cpu"

    # # =========================
    # # 1ï¸âƒ£ éå†æ¯ä¸ª .ptï¼šå¯¼å‡ºå•ç‰©ä½“ PLY + OBJ
    # # =========================
    # for idx, p in enumerate(paths):
    #     print(f"[{idx+1}/{len(paths)}] loading {p}")
    #     out = torch.load(p, map_location=device,weights_only=False)
    #     # è¾“å‡ºout çš„dicté”®
    #     print(f"  Output keys: {list(out.keys())}")

    #     # åªç”¨ make_sceneï¼Œä¸åš ready_gaussian_for_video_rendering
    #     single_scene = make_scene(out)

    #     xyz = single_scene.get_xyz
    #     xyz_cv = xyz.clone()
    #     xyz_cv[:, 1] = -xyz[:, 1]  # Yè½´ç¿»è½¬      
    #     xyz_cv[:, 0] = -xyz[:, 0]  # Xè½´ç¿»è½¬
    #     single_scene.from_xyz(xyz_cv)

    #     stem = os.path.splitext(os.path.basename(p))[0]
    #     # single_ply_path = os.path.join(single_gauss_dir, f"{stem}.ply")
    #     single_ply_path = os.path.join(assets_dir, f"{stem}_gs_target.ply")
    #     single_scene.save_ply(single_ply_path)
    #     print(f"ğŸŸ¢ Saved single-object PLY: {single_ply_path}")
        
    #     # è¾“å‡ºæœªç»transformçš„gaussian
    #     untransforrmed_ply_path = os.path.join(assets_dir, f"{stem}_gs_untransformed.ply")
    #     out["gs"].save_ply(untransforrmed_ply_path)
    #     print(f"ğŸŸ¢ Saved untransformed single-object PLY: {untransforrmed_ply_path}")
        
    #     # æ‰“å°objectçš„poseï¼Œscale
    #     rotation = out['rotation']
    #     translation = out['translation']
    #     scale = out['scale']
    #     print(f" rotation: {out['rotation']}")
    #     print(f" translation: {out['translation']}")
    #     print(f" scale: {out['scale']}")            
        
    #     if out['glb']:
    #         mesh = out['glb']
    #         untransformed_mesh_path = os.path.join(assets_dir, f"{stem}_mesh_untransformed.obj")
    #         mesh.export(untransformed_mesh_path)
    #         print(f"ğŸŸ¢ Saved untransformed object Mesh: {untransformed_mesh_path}")
            
    #         # trimeshåæ ‡ç³»ï¼ˆxå³ï¼Œyå‰ï¼Œzä¸‹ï¼‰è½¬å‘ç›®æ ‡åæ ‡ç³» ï¼ˆxå³ï¼Œyä¸‹ï¼Œzå‰ï¼‰
    #         rot_coordinate_transform = np.array([
    #             [1, 0, 0, 0],
    #             [0, 0, 1, 0],
    #             [0, 1, 0, 0],
    #             [0, 0, 0, 1]
    #         ]) 
    #         first_transformed_mesh_path = os.path.join(assets_dir, f"{stem}_mesh_cooridnates_aligned.obj")
    #         mesh.apply_transform(rot_coordinate_transform)
    #         mesh.export(first_transformed_mesh_path)
    #         print(f"ğŸŸ¢ Saved object mesh whose coordinate aligned with gaussian's: {first_transformed_mesh_path}")
            
    #         # 1. å¤„ç†æ—‹è½¬ï¼šå››å…ƒæ•° â†’ æ—‹è½¬çŸ©é˜µ
    #         quat = out["rotation"].cpu().numpy()  # pytorch3dä¸­å››å…ƒæ•°[w, x, y, z]
    #         rot = R.from_quat(quat,scalar_first=True).as_matrix().squeeze(0) # 3x3

    #         inverse_rot = np.linalg.inv(rot)
    #         # 2. å¤„ç†ç¼©æ”¾
    #         scale = out["scale"].squeeze(0).cpu().numpy() 
    #         if np.isscalar(scale):
    #             scale = np.array([scale, scale, scale])
    #         else:
    #             scale = np.asarray(scale)
            
    #         # æ„å»ºç¼©æ”¾çŸ©é˜µï¼ˆ3x3ï¼‰
    #         scale_mat = np.diag(scale)

    #         # 3. ç»„åˆæ—‹è½¬ + ç¼©æ”¾ï¼šå…ˆç¼©æ”¾ï¼Œå†æ—‹è½¬ï¼ˆé€šå¸¸é¡ºåºï¼‰
    #         # å³ï¼šR @ S ï¼ˆå¯¹ç‚¹ pï¼šp' = R @ (S @ p) = (R @ S) @ pï¼‰
    #         # rot_scale = rot @ scale_mat  # 3x3  

    #         # 4. æ„å»º 4x4 é½æ¬¡å˜æ¢çŸ©é˜µ
    #         transform = np.eye(4)
    #         transform[:3, :3] = inverse_rot @ scale_mat
    #         transform[:3, 3] = out["translation"].cpu().numpy() 

    #         # 5. åº”ç”¨å˜æ¢åˆ° mesh
    #         mesh.apply_transform(transform)
    #         # x, yè½´å–å
    #         mesh.vertices[:,1] = -mesh.vertices[:,1]
    #         mesh.vertices[:,0] = -mesh.vertices[:,0]
    #         # single_mesh_path = os.path.join(single_gauss_dir, f"{stem}-yz-inverse3.obj")
    #         single_mesh_path = os.path.join(assets_dir, f"{stem}_mesh_transformed.obj")
    #         mesh.export(single_mesh_path)
    #         print(f"ğŸŸ¢ Saved single-object Mesh: {single_mesh_path}")

    #     # å¦‚æœæ˜¾å­˜å¾ˆç´§å¼ ï¼Œå¯ä»¥åœ¨è¿™é‡Œ del single_scene / video ç­‰
    #     del single_scene

    print("âœ… All single-object scenes exported.")

if __name__ == "__main__":
    main()
